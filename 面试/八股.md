### 智能指针

智能指针是一种C++中用于管理动态分配内存的指针，通过使用智能指针可以更安全、方便地管理内存，避免内存泄漏等问题。以下是C++中常见的几种智能指针：

1. unique_ptr：独占智能指针，只能有一个指针指向被管理的对象，不能进行复制或赋值操作，但可以进行移动操作。
2. shared_ptr：共享智能指针，可以有多个指针指向被管理的对象，采用引用计数的方式实现内存管理，当最后一个指针离开作用域时，自动释放内存。
3. weak_ptr：弱引用智能指针，是shared_ptr的一种扩展，它可以指向由shared_ptr管理的对象，但并不增加引用计数，不影响对象的生命周期。
4. auto_ptr：已被弃用，被unique_ptr所取代。

### 虚函数

C++中的虚函数是用于实现运行时多态的一种机制，可以在基类中声明虚函数，在派生类中重写它们以实现多态性。

虚函数的实现原理是在对象的内存布局中添加一个虚函数表（vtable），这个表中存储了该类的虚函数地址。当调用一个虚函数时，会先根据对象的类型找到对应的虚函数表，然后再通过表中的虚函数地址调用相应的虚函数。这样，就可以实现对派生类对象中重写的虚函数的正确调用。

构造函数可以是虚函数，但是析构函数必须是虚函数，否则会出现内存泄漏的情况。在使用普通指针（非智能指针）时，如果基类的析构函数不是虚函数，当使用delete删除基类指针时，只会调用基类的析构函数，而不会调用派生类的析构函数，从而导致派生类对象中的资源得不到释放，造成内存泄漏。而使用虚析构函数可以解决这个问题，因为使用delete删除派生类对象的指针时，会先调用派生类的析构函数，再调用基类的析构函数，从而确保派生类对象中的资源得到释放。

内联函数可以是虚函数，但这样做没有意义，因为内联函数的实现方式是在编译期间展开，而虚函数的调用是在运行时进行的，二者的实现机制不同。此外，虚函数的调用需要在虚函数表中查找函数地址，而内联函数的调用则直接将函数体插入到调用处，所以将内联函数声明为虚函数是没有必要的。

### 函数对象

函数对象是一种行为类似于函数的对象，可以像函数一样调用。在C++中，函数对象是一个类，它重载了函数调用运算符 operator()，可以像函数一样被调用。

函数对象在C++中广泛应用于STL容器和算法中，比如sort()函数，它需要一个比较函数来指定排序规则，这个比较函数可以是一个函数对象。又比如for_each()函数，它需要一个处理函数来对容器中的元素进行操作，这个处理函数也可以是一个函数对象。

函数对象的优势在于可以使用面向对象的技术，将函数与相关的数据封装在一起，可以更加灵活地控制函数的行为。此外，函数对象还可以维护一些状态信息，以便在不同的调用之间保持一些中间状态。这种状态信息可以通过成员变量来实现。

下面是一个简单的函数对象示例，它将两个数相加：

```c++
cppCopy code
class Adder {
public:
    int operator()(int a, int b) const {
        return a + b;
    }
};
```

这个函数对象实现了一个operator()运算符，可以将两个数相加并返回它们的和。这样，就可以像使用函数一样使用这个函数对象：

```c++
cppCopy code
Adder add;
int sum = add(3, 4); // sum = 7
```

函数对象在STL中的应用非常广泛，比如STL容器和算法都可以接受函数对象作为参数，以实现不同的功能。例如，可以使用函数对象作为比较函数来对容器进行排序，也可以使用函数对象作为处理函数来对容器中的元素进行处理。

### 左值右值

在C++中，++i和i++都是自增运算符，用于将变量的值增加1。它们的返回值都是变量自增后的值，但是它们的行为略有不同，具体如下：

- ++i先将变量i自增1，然后返回自增后的值，因此++i返回的是自增后的值。
- i++先返回变量i的值，然后再将i自增1，因此i++返回的是自增前的值。

由于++i会先将变量自增后再返回，因此其返回值可以作为左值。这意味着我们可以将++i作为赋值运算符的左操作数，例如：

```c++
cppCopy code
int i = 1;
++i = 2; // 合法，将变量i的值修改为2
```

而i++返回的是自增前的值，不能作为左值。因此，将i++作为赋值运算符的左操作数是不合法的，例如：

```c++
cppCopy code
int i = 1;
i++ = 2; // 不合法，i++返回的是自增前的值，不能作为左值
```

需要注意的是，将++i作为左值时，需要注意变量的生命周期和作用域，避免出现未定义的行为。

### 动态链接

在编译和链接一个程序时，静态链接和动态链接是两种不同的链接方式。

静态链接是将所有程序依赖的库文件都打包到可执行文件中，使得生成的可执行文件可以独立运行，不需要依赖外部库文件。静态链接的好处是可移植性好，可以在不同的系统上运行，不受库文件版本的影响。但是，静态链接会增加可执行文件的大小，浪费磁盘空间，而且如果库文件更新了，需要重新编译程序才能使用新的库文件。

动态链接是在程序运行时，将程序所依赖的库文件从系统中动态加载到内存中，程序在运行时调用这些库文件中的函数。动态链接的好处是减小了可执行文件的大小，不会浪费磁盘空间，而且多个程序可以共享同一个库文件，节省内存。但是，动态链接需要依赖系统中已经安装的库文件，如果系统中没有这些库文件或者库文件版本不兼容，程序将无法运行。

因此，选择静态链接还是动态链接，需要根据实际情况和需求进行选择。一般来说，对于一些稳定的库文件，建议使用静态链接，对于一些常更新的库文件，建议使用动态链接。

### malloc new

`malloc` 和 `new` 是用于在 C++ 中动态分配内存的两种方法。它们之间的主要区别如下：

1. `malloc` 是 C 语言中的函数，而 `new` 是 C++ 中的运算符。因此，`new` 可以使用 C++ 的所有特性（例如异常处理），而 `malloc` 不行。
2. `malloc` 只是分配内存，而 `new` 在分配内存的同时会调用对象的构造函数来初始化对象。
3. `malloc` 返回 `void*` 类型的指针，需要进行显式的类型转换，而 `new` 返回所分配对象的类型指针。
4. `new` 可以自动计算所需的内存空间大小，而 `malloc` 必须显式指定所需的字节数。
5. `new` 可以重载，而 `malloc` 不能。
6. `new` 和 `delete` 是成对使用的，`new` 分配的内存必须由相应的 `delete` 释放；而 `malloc` 和 `free` 是成对使用的，`malloc` 分配的内存必须由相应的 `free` 释放。

总的来说，`new` 比 `malloc` 更方便和安全，因为它可以处理对象的构造和析构，以及自动计算所需的内存空间大小。但是在一些特殊情况下，比如需要分配大量内存，或者需要与 C 代码交互时，`malloc` 可能更适合。

### Fp16 fp32

在将float16转换为float32时，需要将float16的符号位、指数位和尾数位分别转换为float32的符号位、指数位和尾数位。具体地，可以按照以下步骤进行转换：

1. 获取float16的符号位、指数位和尾数位。
   - 符号位：取float16的第15位。
   - 指数位：取float16的第10到15位，并将它们的值减去15得到实际指数。
   - 尾数位：取float16的第0到9位。
2. 根据float16的符号位、指数位和尾数位计算float32的符号位、指数位和尾数位。
   - 符号位：与float16的符号位相同。
   - 指数位：如果float16的指数位不全为0或全为1，则将实际指数加上127得到float32的指数位；否则，如果float16的指数位全为0，则float32的指数位为0；如果float16的指数位全为1，则float32的指数位为255。
   - 尾数位：将float16的尾数位左移13位得到float32的尾数位，并补上剩余的0。
3. 将float32的符号位、指数位和尾数位合并成一个32位的整数，并将它解释为float32类型的值。

### 虚函数表中函数地址何时确定

C++ 的多态机制通过虚函数（virtual function）和虚函数表（virtual table）来实现。在 C++ 中，当一个类被声明为虚函数时，编译器会自动生成一个虚函数表。虚函数表是一个包含类中所有虚函数的指针的数组，每个虚函数在表中占据一个位置。

在 C++ 中，虚函数表中函数地址的确定和对象的虚表指针的值的确定是在编译期和运行期确定的。

在编译期，编译器会根据虚函数的声明和定义来生成虚函数表，并将虚函数表存储在可执行文件中的只读数据段（.rodata）中。在编译期，对象的虚表指针的值也被确定下来，该值指向虚函数表的地址。

在运行期，当对象调用虚函数时，编译器通过对象的虚表指针找到虚函数表，再根据虚函数在表中的位置找到对应的虚函数地址。因此，虚函数表中函数地址的确定和对象的虚表指针的值的确定是在运行期确定的。

需要注意的是，对于不同的对象，它们的虚表指针值是不同的，因为每个对象都有自己的虚表指针。另外，对于类的继承关系，派生类的虚函数表会包含基类的虚函数表，并在其中添加自己的虚函数。这样，派生类的虚函数表就可以继承基类的虚函数实现，并添加自己的实现。

### NVIDIA GPU的由什么构成，p100一个wrap schedule能调度多少个wrap，sm什么时候会切换不同的wrap

NVIDIA GPU通常由多个Streaming Multiprocessor（SM）和Memory Controller组成。每个SM包含多个CUDA Core（用于执行并行计算）、一定数量的寄存器、共享内存、常量内存和缓存等。Memory Controller用于控制GPU内存的访问和传输。

在NVIDIA Volta架构中，V100 GPU包含80个SM，每个SM能够同时调度64个wrap，即每个Wrap的大小为32个线程，所以一个wrap总共有64 * 32 = 2048个线程。因此，p100 GPU最多可以同时调度80 * 64 = 5120个wrap。

SM中的Wrap Scheduler会按照每个Wrap的程序计数器（Program Counter，PC）值为每个Wrap分配一个时间片，并根据需要在Wrap之间进行切换。当一个Wrap需要等待某些操作（如内存访问）完成时，Wrap Scheduler会将处理器分配给另一个Wrap来执行，并在等待的Wrap就绪后继续执行。Wrap Scheduler通常会在每个Wrap的指令流执行完成或遇到分支、函数调用等需要跳转的指令时，进行Wrap的切换。此外，如果一个Wrap的执行时间超过了指定的时间限制，Wrap Scheduler也可能会强制将处理器分配给另一个Wrap。

### Python装饰器是什么，什么原理

Python装饰器是一种高级语法特性，它允许在运行时修改或增强函数或类的行为。装饰器本质上是一个函数，可以将其用于其他函数或类的定义，以增强其功能或行为。装饰器函数通常用于对目标函数进行包装、修改、扩展等操作，从而实现对目标函数的功能增强。

装饰器的实现原理是通过函数的嵌套和闭包特性实现的。在Python中，函数可以作为参数传递，也可以作为返回值返回。因此，我们可以将装饰器函数定义在另一个函数内部，并将需要装饰的函数作为参数传递给装饰器函数，从而实现对函数的增强。

### vector释放内存

对于需要手动释放内存的情况，可以使用 `swap` 函数来释放 `vector` 对象的内存。`swap` 函数可以交换两个 `vector` 对象的内容和容量，将一个 `vector` 对象中的元素和容量移动到另一个 `vector` 对象中。因此，可以创建一个空的 `vector` 对象，使用 `swap` 函数将待释放的 `vector` 对象与空的 `vector` 对象交换，然后将空的 `vector` 对象销毁，以释放其内存。

### tensor core

TensorCore 是 NVIDIA 公司推出的一种深度学习加速技术，旨在提高 GPU 在进行矩阵乘法运算时的效率。

TensorCore 利用了 NVIDIA 的专有硬件——张量核心（Tensor Cores）来执行低精度（FP16）张量运算。这些张量核心可以在同一时间执行多个乘法和加法操作，从而大幅提高计算速度。这对于深度学习等需要大量矩阵运算的任务来说尤其重要。

TensorCore 技术的出现，使得 GPU 在进行深度学习训练时能够显著提高计算速度，同时也降低了训练模型所需的能量和空间开销。

### 低比特位的GEMM是什么

低比特位的GEMM是指使用低精度数据（通常是8位整数或16位浮点数）来进行矩阵乘法运算（General Matrix Multiply，简称GEMM）的技术。由于低比特位数据需要更少的存储空间和计算资源，因此在深度学习等领域中得到广泛应用，能够在提供准确性的同时，大幅度提高模型训练和推断的效率。

低比特位的GEMM技术在实现上需要使用特殊的算法和硬件设备，例如GPU的Tensor Core。在进行低比特位的GEMM时，通常需要使用量化技术将高精度的权重参数量化到低比特位，然后使用低比特位的数据来进行矩阵乘法计算。在计算完成后，需要再次量化为高精度数据以便进行后续的操作。

低比特位的GEMM技术能够显著提高深度学习模型的训练和推断速度，同时还能降低模型存储和计算资源的要求，因此备受深度学习研究和应用领域的青睐。

### lamda表达式

Lambda 表达式的实现原理是将其转换为一个匿名函数对象，并将其赋值给一个变量或参数。Lambda 表达式中的参数列表和函数体将被封装在该函数对象中，并且该函数对象可以像其他函数一样进行调用。Lambda 表达式通常用于函数式编程和模块化编程中，可以简化代码并提高代码的可读性和可维护性。

### GPU 指令级并行

GPU 指令级并行（Instruction-Level Parallelism，ILP）是指在单个线程内，通过同时执行多条指令来提高计算效率。与传统的 CPU 不同，GPU 通常具有大量的计算单元（例如 CUDA 核心），这些计算单元可以在单个线程内并行执行多条指令，从而实现指令级并行。

GPU 指令级并行的实现基于多种技术和机制，例如流水线、超标量和矢量化等。其中，流水线技术是指将一条指令分为多个阶段，并且在不同阶段并行执行多个指令，以提高执行效率。超标量技术是指在同一个周期内执行多条指令，并且通过多个执行单元来实现指令级并行。矢量化技术则是将多个数据元素打包成矢量或矩阵，从而实现多个数据元素之间的并行计算。

GPU 指令级并行的优势在于，它可以充分利用 GPU 计算单元的并行性，并且可以提高计算效率和吞吐量。然而，实现指令级并行需要克服多种挑战，例如指令依赖、数据相关和资源竞争等，因此需要采用有效的调度和优化技术来实现指令级并行，并且需要针对具体的应用场景进行优化。

### C++ 重载机制以及如何实现的

C++ 中的重载机制是指在同一个作用域中，可以定义多个同名函数或操作符，但它们的参数列表或参数类型必须不同。当程序调用该函数或操作符时，编译器会根据实参的数量、类型和顺序等信息来确定调用哪个函数或操作符。

### bank冲突

在NV的GPU中，每个SM不仅会产生shared memroy之间的bank 冲突，也会产生寄存器之间的bank冲突。这一点对于计算密集型的算子十分重要。像shared memory一样，寄存器的Register File也会被分为几个bank，如果一条指令的的源寄存器有2个以上来自同一bank，就会产生冲突。指令会重发射，浪费一个cycle。

所以需要对参与计算的寄存器重新进行分配和排布,如上图右侧所示。在有些地方，这种方式也可以叫做register分块。