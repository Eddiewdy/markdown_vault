​	本次的多核存储实验将基于champSim模拟器，对cache的预取策略进行对比测试，同时尝试在现有的替换和预取算法上进行性能提升和改进。

## 研究现状调研

### Cache替换算法调研

---------------------

​	Cache替换策略在cache性能提升方面发挥着重要和贡献性的作用。从技术角度来看，它也已成为高效内存管理的主要关键特征之一。因此，在现代计算机的设计中，优秀的替换策略对提升计算机的整体性能至关重要，传统的cache替换策略有LRU，Round Robin等等。同样根据cache的级别不同，使用的cache替换策略也不同，L1和L2 cache由于有非常高的时间局部性以及较小的cache大小，因此LRU替换策略就能满足绝大部分性能要求。目前大多数的替换算法都针对LLC进行优化，本次调研的替换算法也都在LLC上效果较好。

#### DIP替换算法

​	在LRU算法中，如果工作集的大小大于cache的大小，就可能会发生cache抖动，对于这一类的应用，很多cache条目从MRU位置一直降级到LRU位置都没有被命中过，这极大程度上降低了cache的利用率。该论文首先提出了BIP插入策略来提高cache利用率，相比于LRU算法，对于新进入cache的条目，有一定概率放在LRU位置，有一定概率放在MRU位置。最后该论文使用set dueling的机制，将cache进行分组，一部分的cache set采用BIP替换策略，一部分的使用LRU策略，根据两种策略的miss次更新PSEL决策器，来动态更新剩下cache set的替换策略。

<img src="https://wangyidipicgo.oss-cn-hangzhou.aliyuncs.com/image-20221021143205283.png" alt="image-20221021143205283" style="zoom:50%;" />

​	DIP插入策略实现非常容易，不需要对现有cache结构进行任何更改，同时需要不超过2 bytes的空间。DIP将1MB 16路L2缓存的平均MPKI降低了21%，降低了LRU和OPT算法之间三分之二的差距。



#### RRIP替换算法

​	RRIP算法从*re-reference*距离切入，对每一个cache block添加一个2-bit计数器来预测*re-reference*距离，每次新插入的cache条目的计数器设为2^M^–1，每次命中将计数器清零，每次逐出内存块的时候选择计数器为2^M^–1的内存块进行逐出。但是对于抖动的应用场景，SRRIP效果不好。因此该论文在SRRIP的基础上，提出BRRIP，在小概率上将新插入的cache条目的计数器设为2^M^–2，以更好应对抖动的现象。同样为了兼容非抖动的应用和抖动的应用，DRRIP使用*Set Dueling*机制，使用一个PSEL计数器将SRRIP和BRRIP算法根据miss次数进行动态调整。

​	RRIP算法对于每个cache块需要两个bit，同时实现起来只需要在LRU上进行简单改动。将DRRIP在SPEC CPU2006的2MB的LLC中进行性能评价，DRRIP相对于LRU算法的吞吐量提升在4%-10%。

#### Hawkeye替换算法

​	Hawkeye算法通过高效模拟历史最优替换算法来指导当前的替换策略。Hawkeye分为三个部分，第一部分根据cache的历史访问序列，得到每个cache条目的存活区间，跟cache大小进行比较，从而得到当前的cache访问在最有替换策略下是hit还是miss。Hawkeye的第二部分根据第一部分得到的当前cache条目的命中信息，来训练一个PC寻址的3 bit预测器，来决定当前的cache line是否内存友好。Hawkeye的第三部分是cache条目的驱逐方案，该部分在RRIP基础上进行改进，根据cache line是否友好来响应更新RRIP计数器的值，同时驱逐RRIP值为最大的cache块。

​	Hawkeye算法实现简单，空间需求小，在2MB的LLC下仅需要16KB的硬件空间开销。Hawkeye在SPEC 2006 CPU上进行性能评价，总体性能提升为8.4%。

![image-20221021155832682](https://wangyidipicgo.oss-cn-hangzhou.aliyuncs.com/image-20221021155832682.png)

<img src="https://wangyidipicgo.oss-cn-hangzhou.aliyuncs.com/image-20221021155822813.png" alt="image-20221021155822813" style="zoom:50%;" />

### Cache预取算法调研

-----------

​	Cache的预取有效的降低了在Cache未命中时的Miss Penalty，当Cache的局部性难以进一步发掘的时候，选择更优秀的Cache预取策略可以有效提高计算机的整体性能。从目前的研究来看。传统的Cache预取的策略包括基于步长的空间预取策略，典型的包括Next-line预取器，以及适合矩阵运算和流媒体运算的Stream预取器。同样也在应用动态运行的过程中根据Cache污染的次数来动态调整预取的激进程度。除此之外，还有一些常见的预取策略如下。

#### Global History Buffer

​	GHB为以前的预取算法改进硬件实施方案，以更大程度发掘空间相关性。GHB是一个先进先出的miss地址队列，其中包含链表，链表相关联的内容有相同的性质。~~GHB可以分为depth和width两种方案进行预取，~~GHB中最近的记录优先级最高，因此可以提升相关预取的准确率，同时GHB中包括了一个更加完整的cache miss的历史，从而可以更大程度发掘cache访问之间的相关性。

#### Temporal Streaming

​	在真实应用中连续的访存指令常常会横跨很大的内存区域，相关性分布在稀疏的空间范围内，而cache块的大小限制了这种空间局部性的发掘。该文提出了*Spatial Memory Streaming*(SMS)预取策略，该策略能识别一块较大空间内的访问模式，从而将数据提前预取到L1 Cache中，降低Miss Penalty。 SMS由活动生成表(active generation table)和历史模式表(pattern history table)组成。活动生成表用一串比特位来记录处理器访问数据的空间模式，并且将第一个miss的访问PC+偏移作为该空间模式的触发器。历史模式表记录了之前观察到的空间模式，每次访问cache是，会进入历史模式表进行pc+偏移的查找，如果查找到相应的触发器，那么就将该模式的数据内容依次预取到Cache中。

​	SMS在FLEXUS上进行评估，得到结果，SMS可以包含58%的L1预取内容，同时降低65%的片下miss，提供37%的整体性能提升。

#### VLDP

​	本文介绍了可变长度Delta预取器（VLDP），该预取器在物理页面中连续缓存行缺失之间建立增量历史记录，然后使用这些历史记录预测新页面中缓存行丢失的顺序。VLDP不使用PC作为预测的特征，它通过给每一个物理页分配一个DHB来记录当前页面的历史访问偏移和Delta，通过Delta在DPT中进行查找，得到下一个Delta。DPT由多个不同优先级的表组成的，高优先级的表的Delta序列更长，每次查找从高优先级的表开始。同时DPT还支持多种程度的预测，能得到一个序列的预取内容。

​	VLDP相对于最好的PC预测器，性能提升7.1%，相对于最好的不使用PC的预测器性能提升5.8%。

### 实验初步设计

------------

​	根据初步的调研结果，我们将实验的步骤分为以下几个部分。第一，探究不同的L1 Cache大小对性能的影响，第二，探究不同的替换策略配合对预取对性能的影响，第三，在现有预取器的基础上进行改进，尝试进一步提升整体的性能。实验所采用的模拟器为ChampSim，ChampSim是一个开源的基于trace的微处理器模拟器，可以更改模拟器的Cache块大小，不同级别的Cache的相连度，路数等等参数，实现针对性的性能分析。同时ChampSim还支持.cc格式的自定义转移预测、预取、替换的策略，因此本次实验在ChampSim模拟器上进行。

​	同时本次实验所使用的所使用的替换策略包括LRU、预取的策略包括但不限于SMS、VLDP、Bingo三种，具体的实验思路如下。

#### Cache大小对性能的影响

​	一般的L1 cache大小为64KB，我们的实验可以在此基础上更改L1 cache的大小，来观察对应的预取效果的影响

- L1D 64KB
- L1D 128KB
- L1D 256KB

​	同时，针对Cache预取算法进行评估，得到miss率、MPKI等数据进行处理。除此之外，可以将实验扩展到不同的Cache级别，更改L2 Cache和LLC的大小进行同样的测试。

### 不同替换和预取策略对性能的影响

​	Cache的替换策略也会对预取效果产生影响，因此针对常见的Cache替换策略，我们选择DIP、RRIP和Hawkeye在不同应用trace上进行比较，除此之外，可以增加ChampSim模拟的核心数来进一步比较，对于Cache预取策略，我们选择在L1上进行预取的SMS和VLDP进行评估，主要评估指标可以使用：

- 加速比
- MPKI
- 预取的Coverage
- 预取的Accuracy

### 预取的优化方案

​	目前来说，可能采取的预取优化方案有两种。

1. 由于VLDP是不基于PC的预取方案，可能一些基于PC的空间相关性发掘的不充分，同时预取的位置是在L2上，所以基于这一点，我们可以尝试将基于PC的SMS预取和VLDP进行结合使用，以期望能提高系统的性能。
2. 在多核的情况下，多个核心运行不同的应用，由于LLC是多个核心之间共享，一个核心的过于激进的预取可能会影响其他核心的cache miss率，所以基于这一点，我们是否可以对多个核心运行的VLDP进行预取程度的动态调整，包括预取的深度和DPT表的个数进行调整，以寻求整体的性能改进。





