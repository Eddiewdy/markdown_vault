### LOCKUP-FREE INSTRUCTION FETCH/PREFETCH CACHE ORGANIZATION

cache是指存储器层次结构中的一种高速存储器，用于临时存储频繁访问的数据，以提高数据访问速度。缓存的设计基于两个主要原则：局部性原理和时间局部性原理。对cache的访问往往比访问主存的速度快几个数量级，当我们要访问的数据存在在cache中时，就可以快速读取到数据，从而减少存储访问的开销。

目前，提升cache效率的方式有以下两种：

- 减少cache未命中时对主存的访问时间，具体包括对cache设计的调整，包括搜索合适的cache的大小，块的大小等等
- 提高cache的命中率，包括不同替换算法的研究等等

但是在这篇文章发布之前，以上的所有提升cache效率的方法都是默认cache是阻塞式的，即一次只能处理一个请求，在cache miss的情况下，需要等待当前的数据从主存中取回后才能处理下一个cache的请求。这篇文章提出了可以将对cache的数据请求流水线化，这种cache的实现方式使得对于指令执行单元来说，数据的请求变成一个完全透明的操作，同时对一串数据的请求可以重叠起来，从而提高吞吐率。

这篇文章的年代比较久远，所使用的cache结构和目前的还有一定的区别，比如cache到主存的数据交换的单元时word，一个cache block（文章中使用的名字）包括多个word，CPU访问cache的时候使用的地址也是指向一个word，所以在此基础上，再来理解文章中的非阻塞的cache设计。

#### 非阻塞cache添加的硬件结构

- 对于每一个可以流水的cache miss，分配一个MSHR（miss information/status holding register）寄存器
- 一个n路比较器，n是MSHR寄存器的数量，用来比较从存储器传输的数据命中哪一个MSHR
- 一个输入栈用来保存收到的数据，栈的大小为每个块里面的word数乘以MSHR的个数
- 用于更新MSHR信息的电路
- 相应的控制逻辑

关于MSHR寄存器，主要需要保存一下两类信息以支持非阻塞式的cache。第一，正确处理主存返回的数据；第二，通知cache的控制单元数据的命中信息和其他的状态。因此，一个MSHR寄存器包含如下的内容：

- cache地址：用来保存主存返回数据后，应该把数据写入cache的位置
- 输入请求地址：用来记录在后续的请求中，请求的数据正在从主存到cache的传输过程中
- 输入标签（每个word一个）：输入标签
- 传送给CPU标识符（每个word一个）：是否允许cache仅将请求的数据返回给 CPU 请求单元，并同时返回其输入标签
- 在输入栈标识符（每个word一个）：是否允许直接从输入栈中读取数据
- 部分写标识符（每个word一个）：用来表示一个word中哪些byte被写入
- 有效位
- MSHR无效位
- 处理的word数量

![image-20230521003606667](https://wangyidipicgo.oss-cn-hangzhou.aliyuncs.com/image-20230521003606667.png)

#### 非阻塞cache的操作

非阻塞cache对于cache的所有操作可以分为两类，第一类是收到主存返回的word数据的相关操作，对于这类操作，首先要进行MSHR的一下内容进行查询：

- 传送给CPU标识符
- 输入标签
- cache地址
- 部分写标识符
- MSHR无效位
- 有效位

当从主存收到一个word的数据后，首先查询**传送给CPU标识符**，如果被置位，将word和对应的word的tag一起传送给CPU，同时把该word写入**输入栈**。输入栈是一个先进后出的结构，将word单位的数据读出，并根据**cache地址**和**部分写标识符**写入到对应的cache的位置。同时，MSHR的以下内容会被修改：

- 在输入栈标识符
- 部分写标识符
- 处理的word数量
- 有效位

当数据被压到输入栈后，将**在输入栈标识符**置位，当数据从输入栈中弹出随后写入cache中时清零。当一个word被写入cache中或者因为被写覆盖或者MSHR被遗弃，那么将**处理的word数量**加一，当**处理的word数量**溢出时，说明一个block的所有word都已经被处理完，那么将有效位清零。



第二类的操作是CPU对cache的访问操作，对于这一类操作，需要对MSHR一下的内容进行查询：

- 输入请求地址
- 传送给CPU标识符
- 在输入栈标识符
- 部分写标识符
- 有效位
- MSHR无效位

具体来说，首先要查询MSHR的**输入请求地址**、**有效位**、**MSHR无效位**来确定是否命中一个之前的miss请求，对**传送给CPU标识符**、**在输入栈标识符**、**部分写标识符**的查询可以得到以下几种状态之一：

- 部分写状态
- 完全写状态
- 在输入栈状态
- 已经传送给CPU状态

根据这这些状态的组合分别有不同的操作，表格如下：

| 输入     | 部分写状态 | 完全写状态 | 在输入栈状态 | 已经传送给CPU状态 | 操作                                            |
| -------- | ---------- | ---------- | ------------ | ----------------- | ----------------------------------------------- |
| read     | No         | No         | No           | No                | 将对应的传送给CPU标识符置位                     |
| read     | No         | No         | No           | YES               | 从主存中读（bypass）                            |
| read     | No         | No         | YES          | x                 | 从栈中读                                        |
| read     | YES        | No         | x            | x                 | 从主存中读（bypass）                            |
| read     | YES        | YES        | x            | x                 | 从对应的cache中读                               |
| prefetch | x          | x          | x            | x                 | 没有操作                                        |
| write    | x          | x          | x            | x                 | 将数据写入对应的cache，将对应的部分写标识符置位 |

当miss的时候，会分配一个新的MSHR，同时进行以下操作：

- 将有效位置位
- 将MSHR无效位清零
- 将cache地址写入MSHR的cache地址
- 将输入请求地址雪茹MSHR的输入请求地址
- 将对应的传送给CPU标识符置位，其他的清零
- 保存tag
- 将所有的部分写标识清零
- 将所有指向当前cache的MSHR全部清除（设置为无效）

最后的将所有指向当前cache的MSHR全部清除的操作是为了防止来自先前分配的缓存缓冲区块的数据覆盖当前分配的数据。我们要保证在所有的MSHR中只能有唯一的MSHR对应一个cache block，使得在后续的cache请求访问MSHR时，只会最多有一个命中。

最后，文章还讨论了MSHR寄存器的数量设置问题。与set大小一样，获得的性能提升比随着寄存器数量的增加而迅速减少。同时文章也给出了一条定性曲线。由于成本考虑和增加MSHR寄存器数量所获得的性能提升，4个寄存器是文章的推荐选择。

#### 总结

对阻塞式cache而言，在cache未命中时，整个流水线都需要等待其从更高级的cache或主存中取回数据。这样的设计比较简单，但是会严重影响性能（尤其是对于乱序处理器而言）。相比之下，非阻塞cache允许缓存未命中时，流水线仍然可以继续处理其他的内存访问，这就需要一些跟踪这些未命中的指令的机制（如Scoreboard）。这一概念由Kroft在这篇文章中首先提出，采用了名为miss status holding registers (MSHR)的寄存器来存放cache miss指令的信息。除此之外还有一个input stack来存放取回但还没有写入到缓存中的数据。这样的cache设计，带来了很大的好处：

- 提高数据访问效率：非阻塞缓存允许同时进行多个并发的读写操作，而不会发生阻塞。这意味着即使有多个访问请求同时到达缓存，它们可以并行处理，而不需要等待前一个操作完成。这显著提高了数据访问的并发性和效率。
- 减少访问延迟：由于非阻塞缓存能够并行处理多个访问请求，它可以更快地响应读取和写入操作。相比于阻塞缓存，非阻塞缓存可以更快地返回数据，从而降低了访问延迟，提高了系统的响应速度。
- 提高系统吞吐量：通过允许并行处理多个访问请求，非阻塞缓存能够更高效地利用计算资源和存储带宽。这导致系统整体的吞吐量提高，能够更好地满足高并发访问的需求。
- 支持高性能计算：非阻塞缓存对于高性能计算和并行处理非常重要。在这些应用中，有大量的数据访问请求需要同时处理，并且需要尽量减少访问延迟。非阻塞缓存的设计可以满足这些要求，允许并行处理大规模的数据访问操作，从而支持高性能计算任务。
- 改善系统可扩展性：非阻塞缓存的设计可以更好地支持多核处理器和多线程应用程序。由于它允许并发的读写操作，各个核心或线程可以独立地进行访问，而不会相互阻塞。这提高了系统的可扩展性，使得多核处理器能够更好地发挥其计算能力。

